{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=816846997775-7jla3ljq0d27nif715g87kqb63thcuvu.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A57609%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpresentations+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fspreadsheets&state=hvI1nsrZXMZEEYmvemavnNbFlrgnCg&access_type=offline\n"
     ]
    }
   ],
   "source": [
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = ['https://www.googleapis.com/auth/presentations',\n",
    "         'https://www.googleapis.com/auth/spreadsheets']\n",
    "\n",
    "creds = None\n",
    "# The file token.json stores the user's access and refresh tokens, and is\n",
    "# created automatically when the authorization flow completes for the first\n",
    "# time.\n",
    "if os.path.exists('token.json'):\n",
    "    creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "# If there are no (valid) credentials available, let the user log in.\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "            '<PATH_TO_CREDS>', SCOPES)\n",
    "        creds = flow.run_local_server(port=<PORT>)\n",
    "    # Save the credentials for the next run\n",
    "    with open('token.json', 'w') as token:\n",
    "        token.write(creds.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gslides\n",
    "from gslides import (\n",
    "    Frame,\n",
    "    Presentation,\n",
    "    Spreadsheet,\n",
    "    Table,\n",
    "    Series, Chart\n",
    ")\n",
    "from sklearn import datasets\n",
    "gslides.intialize_credentials(creds) #BringYourOwnCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = Presentation.create(name = 'demo pres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spr = Spreadsheet.create(\n",
    "    title = 'demo spreadsheet',\n",
    "    sheet_names = ['demo sheet']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading and pivoting data\n",
    "iris = datasets.load_iris(as_frame = True)['data']\n",
    "mapping = {}\n",
    "target_names = [name.capitalize() for name in datasets.load_iris(as_frame = True)['target_names']]\n",
    "for val, name in enumerate(target_names):\n",
    "    mapping[val] = name\n",
    "iris['target'] = datasets.load_iris(as_frame = True)['target'].map(mapping)\n",
    "iris['key']=iris.groupby(['sepal length (cm)','target']).cumcount()\n",
    "plt_df = iris.pivot(index=['sepal length (cm)','key'], columns='target', values='petal width (cm)').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = Frame.create(df = plt_df,\n",
    "          spreadsheet_id = spr.spreadsheet_id,\n",
    "          sheet_id = spr.sheet_names['demo sheet'],\n",
    "          sheet_name = 'demo sheet',\n",
    "          overwrite_data = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = Series.scatter(series_columns = target_names)\n",
    "ch = Chart(\n",
    "    data = frame.data,\n",
    "    x_axis_column = 'sepal length (cm)',\n",
    "    series = [sc],\n",
    "    title = f'Demo Chart',\n",
    "    x_axis_label = 'Sepal Length',\n",
    "    y_axis_label = 'Petal Width',\n",
    "    legend_position = 'RIGHT_LEGEND',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = Table(\n",
    "    data = iris[iris.columns[0:4]].head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs.add_slide(\n",
    "  objects = [ch, tbl],\n",
    "  layout = (1,2),\n",
    "  title = \"Investigation into Fischer's {{ replace }} dataset\",\n",
    "  notes = \"Data from 1936\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs.template(mapping = {'replace': 'Iris'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:prodigy]",
   "language": "python",
   "name": "conda-env-prodigy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
